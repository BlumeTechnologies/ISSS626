{
  "hash": "0c590290731a17804850969649ef68ce",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take Home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods\"\nauthor: \"Pelle Knegjes\"\ndate: \"Aug 26 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  message: false\n  freeze: true\n---\n\n\n## **Setting the Scene**\n\nHousing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\n\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, **Geographical Weighted Models** were introduced to better calibrate predictive models for housing resale prices.\n\n## **The Task**\n\nIn this take-home exercise, you are required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023.\n\n## **The Data**\n\nFor the purpose of this take-home exercise, **HDB Resale Flat Prices** provided by [**Data.gov.sg**](https://isss626-ay2024-25aug.netlify.app/take-home_ex03b) should be used as the core data set. The study should focus on either three-room, four-room or five-room flat.\n\nBelow is a list of recommended predictors to consider. However, students are free to include other appropriate independent variables.\n\n-   Structural factors\n\n    -   Area of the unit\n\n    -   Floor level\n\n    -   Remaining lease\n\n    -   Age of the unit\n\n    -   Main Upgrading Program (MUP) completed (optional)\n\n-   Locational factors\n\n    -   Proxomity to CBD\n\n    -   Proximity to eldercare\n\n    -   Proximity to foodcourt/hawker centres\n\n    -   Proximity to MRT\n\n    -   Proximity to park\n\n    -   Proximity to good primary school\n\n    -   Proximity to shopping mall\n\n    -   Proximity to supermarket\n\n    -   Numbers of kindergartens within 350m\n\n    -   Numbers of childcare centres within 350m\n\n    -   Numbers of bus stop within 350m\n\n    -   Numbers of primary school within 1km\n\n\n## Data Wrangling\n\nFirst we want to load the following packages to achieve our task:\n\n- sf\n- spdep\n- GWmodel\n- SpatialML\n- tmap\n- rsample\n- Metrics\n- tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, GGally, spdep, tmap, sfdep, plotly, Kendall, SpatialAcc, ggstatsplot, reshape2,httr, jsonlite, rvest, olsrr, gtsummary, performance, see)\n```\n:::\n\n\n# setting seed\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")%>%\n  st_transform(crs = 3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\BlumeTechnologies\\ISSS626\\ISSS626\\Take-Home_Exercises\\Take-Home_Exercise03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale <- read_csv(\"data/aspatial/ResaleflatpricesbasedonregistrationdatefromJan-2017onwards.csv\") %>%\n  filter(month >= \"2023-01\" & month <= \"2024-09\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy <- resale %>%\n  mutate(address = paste(block,street_name)) %>%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%>%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(resale_tidy, \"data/rds/resale_tidy.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_selected <- resale_tidy #%>%\n  #filter(month == \"2024-09\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_list <- sort(unique(resale_selected$address))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nget_coords <- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords <- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords <- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- get_coords(add_list)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(coords, \"data/rds/coords.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- read_rds(\"data/rds/coords.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy <- read_rds(\"data/rds/resale_tidy.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresaleRAW <- left_join(resale_tidy, coords)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(address)`\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale <- st_as_sf(resaleRAW, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)%>%\n  st_jitter(amount = 0.5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nassign_dummy <- function(range) {\n  if (range %in% c(\"01 TO 03\", \"04 TO 06\", \"07 TO 09\", \"10 TO 12\", \n                   \"13 TO 15\", \"16 TO 18\")) {\n    return(1)  # Low\n  } else if (range %in% c(\"19 TO 21\", \"22 TO 24\", \"25 TO 27\", \n                          \"28 TO 30\", \"31 TO 33\", \"34 TO 36\")) {\n    return(2)  # Medium\n  } else {\n    return(3)  # High\n  }\n}\n\n# Apply the function to create a new column in the resale data frame\nresale$floor_level <- sapply(resale$storey_range, assign_dummy)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(resale, \"data/rds/resale.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale <- read_rds(\"data/rds/resale.rds\")\n```\n:::\n\n\n\n# Creating Buffer Zones\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffer350 = st_buffer(resale, dist = 350)\nbuffer1000 = st_buffer(resale, dist = 1000)\n```\n:::\n\n\n\n\n# Loading in locational predictor variables\n::: panel-tabset\n\n## Proximity to CBD\n\n::: {.cell}\n\n```{.r .cell-code}\nCBD <- data.frame(\n  longitude = c(103.8503),  # Example longitudes\n  latitude = c(1.2812)      # Example latitudes\n)\n\nCBD <- st_as_sf(CBD, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndistances = st_distance(resale, CBD)\nmin_distances <- apply(distances, 1, min)\nresale$PROX_CBD = min_distances\n```\n:::\n\n\n## Proximity to Eldercare\n\n::: {.cell}\n\n```{.r .cell-code}\neldercare <- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") %>%\n  st_transform(crs = 3414) \n\ndistances = st_distance(resale, eldercare)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_ELDERLYCARE = min_distances\n```\n:::\n\n\n## Proximity to Hawker centres\n\n::: {.cell}\n\n```{.r .cell-code}\nhawker <- st_read(\"data/geospatial/HawkerCentresGEOJSON.geojson\") %>%\n  st_transform(crs = 3414) \n\ndistances = st_distance(resale, hawker)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_HAWKER = min_distances\n```\n:::\n\n\n## Proximity to MRT\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmrt <- read_csv(\"data/aspatial/MRT.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmrt <- st_as_sf(mrt, \n                       coords = c(\"Longitude\", \"Latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndistances = st_distance(resale, mrt)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_MRT = min_distances\n```\n:::\n\n\n## Proximity to Park\n\n::: {.cell}\n\n```{.r .cell-code}\npark <- st_read(\"data/geospatial/Parks.geojson\")  %>%\n  st_transform(crs = 3414)\n\ndistances = st_distance(resale, park)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_PARK = min_distances\n```\n:::\n\n\n##Proximity to Shopping Mall\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmalls <- read_csv(\"data/aspatial/shopping_mall_coordinates.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmalls <- st_as_sf(malls, \n                       coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\ndistances = st_distance(resale, malls)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_MALL = min_distances\n```\n:::\n\n\n\n## Proximity to Supermarket\n\n::: {.cell}\n\n```{.r .cell-code}\nsupermarket <- st_read(\"data/geospatial/SupermarketsGEOJSON.geojson\") %>%\n  st_transform(crs = 3414) \n\ndistances = st_distance(resale, supermarket)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_SUPERMARKET = min_distances\n```\n:::\n\n\n## Number of Kidergartens within 350m\n\n::: {.cell}\n\n```{.r .cell-code}\nkindergarten <- st_read(\"data/geospatial/Kindergartens.geojson\") %>%\n  st_transform(crs = 3414)\n\nresale$WITHIN_350M_KINDERGARTEN = lengths(\n  st_intersects(buffer350, kindergarten)\n)\n```\n:::\n\n\n## Number of childcare centres within 350m\n\n::: {.cell}\n\n```{.r .cell-code}\nchildcare <- st_read(\"data/geospatial/ChildCareServices.geojson\") %>%\n  st_transform(crs = 3414) \n\n\nresale$WITHIN_350M_CHILDCARE = lengths(\n  st_intersects(buffer350, childcare)\n)\n```\n:::\n\n\n## Numbers of bus stop within 350m\n\n::: {.cell}\n\n```{.r .cell-code}\nbusstop <- st_read(dsn = \"data/geospatial\", layer = \"BusStop\") %>%\n  st_transform(crs = 3414) \n\nresale$WITHIN_350M_BUS = lengths(\n  st_intersects(buffer350, busstop)\n)\n```\n:::\n\n\n## Numbers of primary school within 1km\n\n::: {.cell}\n\n```{.r .cell-code}\nschools <- read_csv(\"data/aspatial/Generalinformationofschools.csv\") %>%\n  filter(mainlevel_code == \"PRIMARY\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_list1 <- sort(unique(schools$address))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nget_coords1 <- function(add_list1){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords1 <- data.frame()\n    \n  for (i in add_list1){\n    #print(i)\n\n    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords1 <- rbind(postal_coords1, new_row)\n  }\n  return(postal_coords1)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoordsschool <- get_coords(add_list1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(coordsschool, \"data/rds/coordsschool.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoordsschool <- read_rds(\"data/rds/coordsschool.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nschools <- left_join(schools, coordsschool)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nschools <- st_as_sf(schools, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale$WITHIN_1KM_SCHOOL = lengths(\n  st_intersects(buffer1000, schools)\n)\n```\n:::\n\n\n## Proximity to Good Primary School\n\n::: {.cell}\n\n```{.r .cell-code}\ngoodschools = c(\"AI TONG SCHOOL\", \"ANGLO-CHINESE SCHOOL (JUNIOR)\", \"ANGLO-CHINESE SCHOOL (PRIMARY)\",\"CATHOLIC HIGH SCHOOL (PRIMARY SECTION)\", \"CHIJ ST. NICHOLAS GIRLS’ SCHOOL (PRIMARY SECTION)\", \"CHONGFU SCHOOL\",\n\"FAIRFIELD METHODIST SCHOOL (PRIMARY)\", \"GONGSHANG PRIMARY SCHOOL\",\n\"HENRY PARK PRIMARY SCHOOL\", \"HOLY INNOCENTS' PRIMARY SCHOOL\",\n\"HORIZON PRIMARY SCHOOL\", \"METHODIST GIRLS' SCHOOL (PRIMARY)\",\"NAN HUA PRIMARY SCHOOL\", \"NANYANG PRIMARY SCHOOL\",\n\"NORTHLAND PRIMARY SCHOOL\", \"PEI CHUN PUBLIC SCHOOL\",\n\"PEI HWA PRESBYTERIAN PRIMARY SCHOOL\", \"RED SWASTIKA SCHOOL\",\n\"ROSYTH SCHOOL\", \"RULANG PRIMARY SCHOOL\", \"SOUTH VIEW PRIMARY SCHOOL\", \"ST. HILDA'S PRIMARY SCHOOL\", \"ST. JOSEPH'S INSTITUTION JUNIOR\", \"TAO NAN SCHOOL\", \"TEMASEK PRIMARY SCHOOL\")\n\ngood_schools = schools %>%\n  filter(school_name %in% goodschools)\n\n\ndistances = st_distance(resale, good_schools)\n\nmin_distances <- apply(distances, 1, min)\nresale$PROX_GOOD_PRISCH = min_distances\n```\n:::\n\n\n\n:::\n\n\n\n\n\n# tidiy-ing data\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy = resale %>%\n  select(resale_price, floor_area_sqm, floor_level,  remaining_lease_yr,PROX_CBD, PROX_ELDERLYCARE, PROX_HAWKER, PROX_MRT, PROX_PARK, PROX_GOOD_PRISCH, PROX_MALL, PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, WITHIN_350M_BUS, WITHIN_1KM_SCHOOL,month, flat_type,flat_model, storey_range, lease_commence_date, remaining_lease_mth, address, remaining_lease, ,postal, geometry)\n```\n:::\n\n\n\n# Data Sampling\n\n## Creating subsets\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for data from the year 2023\nsubset_2023 <- resale_tidy %>%\n  filter(grepl(\"^2023-\", month) & flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\n# Filter for data between July and September 2024\nsubset_jul_sep_2024 <- resale_tidy %>%\n  filter(month %in% c(\"2024-07\", \"2024-08\", \"2024-09\") & flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(subset_jul_sep_2024, \"data/rds/test_data.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- read_rds(\"data/rds/test_data.rds\")\n```\n:::\n\n\n\n## creating training data\n\nDue to processing limitations we will need to reduce the number of observations in our training dataset.\n\n::: {.cell}\n\n```{.r .cell-code}\noriginal_size <- nrow(subset_2023)\noriginal_size\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_size <- 5000\n```\n:::\n\n\nRandom Sampling: The sample_n() function is used to randomly select 5000 observations from the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ntrain_data <- subset_2023 %>%\n    sample_n(size = sample_size, replace = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(train_data, \"data/rds/train_data.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- read_rds(\"data/rds/train_data.rds\")\n```\n:::\n\n\n\n\n# Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnogeo_2023 <- train_data %>%\n  st_drop_geometry()\ncorrplot::corrplot(cor(nogeo_2023[, 1:16]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-53-1.png){width=1152}\n:::\n:::\n\n\nThe correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicolinearity.\n\n\n\n# Building a Hedonic Pricing Model by using Multiple Linear Regression Method\n# Building a non-spatial multiple linear regression\n\n\n\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_mlr <- lm(formula = resale_price ~ floor_area_sqm + floor_level + remaining_lease_yr + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +PROX_MRT + PROX_PARK + PROX_GOOD_PRISCH + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_SCHOOL,\n                  data=train_data)\nsummary(resale_mlr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(resale_mlr, \"data/rds/resale_mlr.rds\" ) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_mlr <- read_rds(\"data/rds/resale_mlr.rds\")\n```\n:::\n\n# Model Assessment: olsrr method\n\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\n- comprehensive regression output\n- residual diagnostics\n- measures of influence\n- heteroskedasticity tests\n- model fit assessment\n- variable contribution assessment\n- variable selection procedures\n\n# Generating tidy linear regression report\n\n::: {.cell}\n\n```{.r .cell-code}\nols_regress(resale_mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.899       RMSE                    68982.259 \nR-Squared                   0.808       MSE                4773828300.418 \nAdj. R-Squared              0.807       Coef. Var                  12.344 \nPred R-Squared              0.806       AIC                    125639.432 \nMAE                     51860.197       SBC                    125750.224 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                      \n-------------------------------------------------------------------------------\n                    Sum of                                                     \n                   Squares          DF       Mean Square       F          Sig. \n-------------------------------------------------------------------------------\nRegression    1.000766e+14          15      6.671772e+12    1397.573    0.0000 \nResidual      2.379276e+13        4984    4773828300.418                       \nTotal         1.238693e+14        4999                                         \n-------------------------------------------------------------------------------\n\n                                                 Parameter Estimates                                                  \n---------------------------------------------------------------------------------------------------------------------\n                   model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n---------------------------------------------------------------------------------------------------------------------\n             (Intercept)    -173309.721      8916.656                 -19.437    0.000    -190790.291    -155829.152 \n          floor_area_sqm       5254.162        54.899        0.631     95.706    0.000       5146.536       5361.788 \n             floor_level     112895.436      3891.341        0.194     29.012    0.000     105266.695     120524.177 \n      remaining_lease_yr       5169.963        73.728        0.500     70.122    0.000       5025.423       5314.503 \n                PROX_CBD        -15.110         0.318       -0.417    -47.504    0.000        -15.734        -14.487 \n        PROX_ELDERLYCARE         -8.643         1.739       -0.034     -4.970    0.000        -12.053         -5.234 \n             PROX_HAWKER        -28.488         2.171       -0.094    -13.122    0.000        -32.744        -24.231 \n                PROX_MRT        -23.829         2.825       -0.058     -8.435    0.000        -29.367        -18.291 \n               PROX_PARK        -11.405         2.653       -0.031     -4.299    0.000        -16.606         -6.204 \n        PROX_GOOD_PRISCH         -1.705         0.843       -0.014     -2.022    0.043         -3.358         -0.052 \n               PROX_MALL         -5.746         3.010       -0.014     -1.909    0.056        -11.646          0.155 \n        PROX_SUPERMARKET          4.027         6.404        0.004      0.629    0.530         -8.529         16.582 \nWITHIN_350M_KINDERGARTEN       8187.352      1105.089        0.053      7.409    0.000       6020.892      10353.813 \n   WITHIN_350M_CHILDCARE      -2171.257       528.929       -0.031     -4.105    0.000      -3208.190      -1134.323 \n         WITHIN_350M_BUS         33.593       364.145        0.001      0.092    0.927       -680.291        747.477 \n       WITHIN_1KM_SCHOOL      -2084.913       775.082       -0.020     -2.690    0.007      -3604.414       -565.411 \n---------------------------------------------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n# Multicolinearuty\n\n::: {.cell}\n\n```{.r .cell-code}\nols_vif_tol(resale_mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  Variables Tolerance      VIF\n1            floor_area_sqm 0.8876293 1.126596\n2               floor_level 0.8646552 1.156530\n3        remaining_lease_yr 0.7590403 1.317453\n4                  PROX_CBD 0.4997118 2.001154\n5          PROX_ELDERLYCARE 0.8091410 1.235879\n6               PROX_HAWKER 0.7461858 1.340149\n7                  PROX_MRT 0.8229885 1.215084\n8                 PROX_PARK 0.7200841 1.388727\n9          PROX_GOOD_PRISCH 0.7685066 1.301225\n10                PROX_MALL 0.7558033 1.323096\n11         PROX_SUPERMARKET 0.8592631 1.163788\n12 WITHIN_350M_KINDERGARTEN 0.7568912 1.321194\n13    WITHIN_350M_CHILDCARE 0.6601779 1.514743\n14          WITHIN_350M_BUS 0.8621027 1.159955\n15        WITHIN_1KM_SCHOOL 0.6742910 1.483039\n```\n\n\n:::\n:::\n\n\n# Variable Selection\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_fw_mlr <- ols_step_forward_p(\n  resale_mlr,\n  p_val = 0.05,\n  details = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(resale_fw_mlr)\n```\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n:::\n\n\n# Visualising model parameters\n\n::: {.cell}\n\n```{.r .cell-code}\nggcoefstats(resale_mlr,\n            sort = \"ascending\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-61-1.png){width=672}\n:::\n:::\n\n# Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\n\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_plot_resid_fit(resale_fw_mlr$model)\n```\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n# Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_plot_resid_hist(resale_fw_mlr$model)\n```\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-63-1.png){width=672}\n:::\n:::\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_test_normality(resale_fw_mlr$model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.964          0.0000 \nKolmogorov-Smirnov        0.048          0.0000 \nCramer-von Mises         421.9155        0.0000 \nAnderson-Darling         24.1198         0.0000 \n-----------------------------------------------\n```\n\n\n:::\n:::\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n# Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\n\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr_output <- as.data.frame(resale_fw_mlr$model$residuals) %>%\n  rename(`FW_MLR_RES` = `resale_fw_mlr$model$residuals`)\n```\n:::\n\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_sf <- cbind(train_data, \n                        mlr_output$FW_MLR_RES) %>%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n```\n:::\n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\nThe code churn below will turn on the interactive mode of tmap.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The shape mpsz is invalid. See sf::st_is_valid\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-67-1.png){width=672}\n:::\n:::\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\n# Spatial stationary test\nTo proof that our observation is indeed true, the Moran’s I test will be performed\n\nHo: The residuals are randomly distributed (also known as spatial stationary) \n\nH1: The residuals are spatially non-stationary\n\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_sf <- condo_resale_sf %>%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n```\n:::\n\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.54398, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\n\nSince the Observed Global Moran I = 0.54398 which is greater than 0, we can infer than the residuals resemble cluster distribution.\n\n\n# gwr predictive method\nIn this section, we will calibrate a model to predict the resale price by using geographically weighted regression methods of the GWmodel package.\n\n## Converting the sf data.frame to SpatialPointDataFrame\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclass       : SpatialPointsDataFrame \nfeatures    : 5000 \nextent      : 11806.62, 45192.04, 28097.21, 48682.57  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 25\nnames       : resale_price, floor_area_sqm, floor_level, remaining_lease_yr,         PROX_CBD,  PROX_ELDERLYCARE,      PROX_HAWKER,         PROX_MRT,        PROX_PARK, PROX_GOOD_PRISCH,         PROX_MALL,   PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, WITHIN_350M_BUS, ... \nmin values  :       255000,             52,           1,                 42, 666.644171819409, 0.179647493572076, 6.79525704960773, 43.4480854308872, 69.1086103057036, 49.5189588300732, 0.408661136877515, 0.0574108534731242,                        0,                     0,               0, ... \nmax values  :      1450000,            153,           3,                 95, 20122.7129321506,  4767.18822737805, 2830.83991796497, 3453.82285464761, 2412.04585964894, 7508.35652041974,  3158.74708636409,     3325.044142153,                        8,                    18,              18, ... \n```\n\n\n:::\n:::\n\n\n\n## Computing adaptive bandwidth\nNext, bw.gwr() of GWmodel package will be used to determine the optimal bandwidth to be used.\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + floor_level + remaining_lease_yr + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +PROX_MRT + PROX_PARK + PROX_GOOD_PRISCH + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_SCHOOL,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(bw_adaptive, \"data/rds/bw_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_adaptive <- read_rds(\"data/rds/bw_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_adaptive\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 124\n```\n\n\n:::\n:::\n\n\n## Converting the test data from sf data.frame to SpatialPointDataFrame\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_sp <- test_data %>%\n  as_Spatial()\ntest_data_sp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclass       : SpatialPointsDataFrame \nfeatures    : 7123 \nextent      : 11596.89, 45191.96, 28156.76, 48741.3  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 25\nnames       : resale_price, floor_area_sqm, floor_level, remaining_lease_yr,         PROX_CBD,   PROX_ELDERLYCARE,      PROX_HAWKER,         PROX_MRT,        PROX_PARK, PROX_GOOD_PRISCH,        PROX_MALL,   PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, WITHIN_350M_BUS, ... \nmin values  :       265000,             52,           1,                 41, 887.401166574681, 0.0999312900833446, 14.8228604871382, 38.9803310461812,  69.143887333333, 49.6977363022803, 5.00086325658124, 0.0418611341137161,                        0,                     0,               0, ... \nmax values  :      1580000,          366.7,           3,                 95, 20022.7271065088,   4767.47271007617, 2844.96315812187, 3454.33030433379, 2398.58996780088, 7450.10801675436,   3159.257578435,    3325.1938900491,                        7,                    22,              18, ... \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_bw_test_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + floor_level + remaining_lease_yr + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +PROX_MRT + PROX_PARK + PROX_GOOD_PRISCH + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_SCHOOL,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwr_bw_test_adaptive, \"data/rds/gwr_bw_test_adaptive.rds\")\n```\n:::\n\n\n# Preparing coordinates data\n## Extracting coordinates data\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train <- write_rds(coords_train, \"data/rds/coords_train.rds\" )\ncoords_test <- write_rds(coords_test, \"data/rds/coords_test.rds\" )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train = read_rds(\"data/rds/coords_train.rds\")\ncoords_test <- read_rds(\"data/rds/coords_test.rds\")\n```\n:::\n\n\n## Droping geometry field\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- train_data %>% \n  st_drop_geometry()\n```\n:::\n\n\n# Calibrating Random Forest Model\n\nGeographically Weighted Random Forest (GRF) is a spatial analysis method using a local version of the famous Machine Learning algorithm.\n\nThis technique adopts the idea of the Geographically Weighted Regression.\n\nThe main difference between a tradition (linear) GWR and GRF is that we can model non-stationarity coupled with a flexible non-linear model which is very hard to overfit due to its bootstrapping nature, thus relaxing the assumptions of traditional Gaussian statistics.\n\n\n# Calibrating Geographical Random Forest Model\nIn this section, we will calibrate a model to predict resale price by using grf() of SpatialML package.\n\n## Calibrating using training data\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + floor_level + \n                  remaining_lease_yr +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_GOOD_PRISCH + PROX_MALL                 + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_SCHOOL,\n                     dframe=train_data, \n                     bw=bw_adaptive,\n                     kernel=\"adaptive\",\n                     coords=coords_train,\n                  ntree = 50)\n```\n:::\n\n\n\nLet’s save the model output by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwRF_adaptive, \"data/rds/gwRF_adaptive.rds\")\n```\n:::\n\n\nThe code chunk below can be used to retrieve the save model in future.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- read_rds(\"data/rds/gwRF_adaptive.rds\")\n```\n:::\n\n\n\n\n\n## Predicting by using test data\n### Preparing the test data\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n```\n:::\n\n\n###  Predicting with test data\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_pred <- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- write_rds(gwRF_pred, \"data/rds/GRF_pred.rds\")\n```\n:::\n\n\n### Converting the predicting output into a data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- read_rds(\"data/rds/GRF_pred.rds\")\nGRF_pred_df <- as.data.frame(GRF_pred)\n```\n:::\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_p <- cbind(test_data, GRF_pred_df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(test_data_p, \"data/rds/test_data_p.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_p <- read_rds(\"data/rds/test_data_p.rds\")\n```\n:::\n\n\n## Calculating Mean Errors and R2\n\n::: {.cell}\n\n```{.r .cell-code}\nactual_prices <- test_data_p$resale_price\npredicted_prices <- test_data_p$GRF_pred \n\n# Calculate Mean Absolute Error (MAE)\nmae <- mean(abs(actual_prices - predicted_prices))\n\n# Calculate Mean Squared Error (MSE)\nmse <- mean((actual_prices - predicted_prices)^2)\n\n# Calculate Root Mean Squared Error (RMSE)\nrmse <- sqrt(mse)\n\n# Calculate R-squared (R²)\nss_total <- sum((actual_prices - mean(actual_prices))^2)\nss_residual <- sum((actual_prices - predicted_prices)^2)\nr_squared <- 1 - (ss_residual / ss_total)\n\n# Print the results\ncat(\"Mean Absolute Error (MAE):\", mae, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Absolute Error (MAE): 63282.2 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean Squared Error (MSE):\", mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Squared Error (MSE): 8123804666 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Root Mean Squared Error (RMSE):\", rmse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRoot Mean Squared Error (RMSE): 90132.15 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"R-squared (R²):\", r_squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR-squared (R²): 0.7412435 \n```\n\n\n:::\n:::\n\n\n## Visualising the predicted values\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = test_data_p, aes(x = GRF_pred, y = resale_price))  +\n  geom_point() +  # Add scatter plot points\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +  # Add regression line\n  labs(title = \"Scatter Plot with Regression Line\",\n       x = \"Predicted Price\",\n       y = \"Actual Price\") +  # Add labels\n  theme_minimal()  # Optional: use a minimal theme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-Home_Exercise03_files/figure-html/unnamed-chunk-93-1.png){width=672}\n:::\n:::\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "Take-Home_Exercise03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}